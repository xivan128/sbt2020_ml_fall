{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейный SVM \"своими руками\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерируем обучающую и тестовую выборку для экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_classification(\n",
    "    n_samples=10000, n_features=20, \n",
    "    n_classes=2, n_informative=20, \n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(len(X), len(y))\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 20)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем свой класс для SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "class MySVM(object):\n",
    "    def __init__(self, C=10000):\n",
    "        self.C = C # regularization constant\n",
    "\n",
    "    # f(x) = <w,x> + w_0\n",
    "    def f(self, x):\n",
    "        a=self.w\n",
    "        b=np.array([self.w0])\n",
    "        c= np.hstack((a,b ))\n",
    "        d=np.hstack((x,[1]))\n",
    "        ret=np.dot(c, d)\n",
    "        #print(ret, c)\n",
    "        return ret\n",
    "\n",
    "    # a(x) = [M(x) > 0]\n",
    "   \n",
    "    def a(self, x):\n",
    "        return 1 if self.f(x) > 0 else 0\n",
    "    \n",
    "    # predicting answers for X_test\n",
    "    def predict(self, X_test):\n",
    "        return np.array([model.a(x) for x in X_test])\n",
    "\n",
    "    # l2-regularizator\n",
    "    def reg(self):\n",
    "        return 1.0 * sum(self.w ** 2) / (2.0 * self.C)\n",
    "\n",
    "    # l2-regularizator derivative\n",
    "    def der_reg(self):\n",
    "        der=self.w/self.C\n",
    "        '''done ToDo: fix this function'''\n",
    "        return der\n",
    "\n",
    "    # hinge loss\n",
    "    def loss(self, x, answer):\n",
    "        return max([0, 1 - answer * self.f(x)])\n",
    "\n",
    "    # hinge loss derivative\n",
    "    def der_loss(self, x, answer):\n",
    "        if self.loss(x, answer) > 0:\n",
    "            return -np.dot(x.T, answer)\n",
    "        return 0\n",
    "\n",
    "    # fitting w and w_0 with SGD\n",
    "    def fit(self, X_train, y_train):\n",
    "        dim = len(X_train[0])\n",
    "        self.w = np.random.rand(dim) # initial value for w\n",
    "        self.w0 = np.random.randn() # initial value for w_0\n",
    "        \n",
    "        # 10000 steps is OK for this example\n",
    "        # another variant is to continue iterations while error is still decreasing\n",
    "        for k in range(10000):  \n",
    "            \n",
    "            # random example choise\n",
    "            rand_index = randint(0, len(X_train) - 1) # generating random index\n",
    "            x = X_train[rand_index]\n",
    "            y = y_train[rand_index]\n",
    "\n",
    "            # simple heuristic for step size\n",
    "            step = 0.5 / math.sqrt(k+1)\n",
    "\n",
    "            # w update\n",
    "            self.w-=step*(self.der_loss(X_train[rand_index],  y_train[rand_index])+self.der_reg())\n",
    "            #self.w-=step*self.der_loss(X_train[rand_index],  y_train[rand_index])\n",
    "            \n",
    "            '''done: ToDo: add w update with regularization'''\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пробуем обучить наш классификатор и посмотреть на качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.629852   -0.32367627  0.02432447  1.19340314 -0.73944938  0.32239867\n",
      " -0.80184796  0.53560415 -0.76134059 -1.08557651 -0.10890644  0.28654643\n",
      "  1.19131481  0.33786879 -0.4180304   0.22841889  0.22822097  0.65795351\n",
      " -0.07578072  0.14554457] -1.0128311203344238\n"
     ]
    }
   ],
   "source": [
    "model = MySVM()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.w, model.w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 1] 2000 991\n"
     ]
    }
   ],
   "source": [
    "print(y_test, len(y_test), sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 1207\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions), sum(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "print(sum(predictions == y_test) / float(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задания:\n",
    "\n",
    "### - Допишите недостающие функции в MySVM (производные и обновление весов)\n",
    "\n",
    "### - Сравните качество с sklearn LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellib=LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "modellib.fit(X_train, y_train)\n",
    "#print(modellib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionslib = modellib.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictionslib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 1015\n"
     ]
    }
   ],
   "source": [
    "print(len(predictionslib), sum(predictionslib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801\n"
     ]
    }
   ],
   "source": [
    "print(sum(predictionslib == y_test) / float(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
